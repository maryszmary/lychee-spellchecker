{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel():\n",
    "    def __init__(self, order=2):\n",
    "        self.order=order\n",
    "        \n",
    "    def product(self, nums):\n",
    "        \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "        result = 1\n",
    "        for x in nums: result *= x\n",
    "        return result\n",
    "\n",
    "    def get_ngrams(self, tokens, n):\n",
    "        return [' '.join(tokens[i:i+n]) for i, token in enumerate(tokens)]\n",
    "    \n",
    "    def get_counts(self, corpus, order):  \n",
    "        counts = {'n' + str(i) : Counter(self.get_ngrams(corpus, n=i)) for i in range(1, order+1)}\n",
    "        counts['n0'] = {'':len(corpus)}\n",
    "        return counts\n",
    "    \n",
    "    def get_prob(self, counts, word, context=''):\n",
    "        '''With Laplace shoothing as yet.\n",
    "        Not for public use.'''\n",
    "        order = len(context.split())+1\n",
    "        separator = ' ' if order > 1 else ''\n",
    "        return (counts['n'+str(order)][separator.join([context, word])] + 1) / \\\n",
    "               (counts['n'+str(order-1)][context] + len(counts['n'+str(order)]))\n",
    "        \n",
    "    def get_logprob(self, counts, word, context=''):\n",
    "        return np.log(self.get_prob(counts, word, context))\n",
    "    \n",
    "    def get_following(self, counts, context):\n",
    "        '''Slow as hell. \n",
    "        To optimize might use embedded dictionaries.'''\n",
    "        order = len(context.split())+1\n",
    "        return sorted(\n",
    "            [(k.split()[-1], v, self.get_prob(counts, k.split()[-1], context)) \\\n",
    "            for k, v in counts['n'+str(order)].items()                         \\\n",
    "            if re.match(context+' '+'\\w+', k)],                                \\\n",
    "            key=lambda x:x[1], reverse=True)   \n",
    "    \n",
    "    def get_string_probs(self, counts, string, order, log=True):\n",
    "        prob_fun = self.get_logprob if log else self.get_prob\n",
    "        tokens = string.split()\n",
    "        probs = []\n",
    "        for i in range(len(tokens)):\n",
    "            context = ' '.join(tokens[i-order+1:i]) if i>=order else ' '.join(tokens[:i])\n",
    "            prob = prob_fun(counts, word = tokens[i], context = context)\n",
    "            probs.append(prob)\n",
    "        return probs\n",
    "    \n",
    "    def interpolate(self, counts, string, order, log=True, lambdas='default'):\n",
    "        lmbd = [0.3, 0.7, 0.0] if lambdas == 'default' else lambdas\n",
    "        aggregate = sum if log else self.product\n",
    "        probs = [self.get_string_probs(counts, string, order=i, log=log) \\\n",
    "                 for i in range(1, order+1)]\n",
    "        probs_interpolated = []\n",
    "        for tup in zip(*probs):\n",
    "            prob_token = 0\n",
    "            for i in range(len(tup)):\n",
    "                prob_token += tup[i] * lmbd[i]\n",
    "            probs_interpolated.append(prob_token)\n",
    "        return aggregate(probs_interpolated)\n",
    "    \n",
    "    def fit(self, corpus):\n",
    "        self.counts = self.get_counts(corpus, self.order)\n",
    "        \n",
    "    def prob(self, string, log=False):\n",
    "        return self.interpolate(self.counts, string, self.order, log=log)\n",
    "    \n",
    "    def context_prob(self, word, context='', log=False):\n",
    "        prob_fun = self.get_logprob if log else self.get_prob\n",
    "        c = context.split()\n",
    "        history = ' '.join(c) if len(c) < self.order else ' '.join(c[-self.order+1:])\n",
    "        return prob_fun(self.counts, word, history)  \n",
    "    \n",
    "    def following(self, context):\n",
    "        c = context.split()\n",
    "        history = ' '.join(c) if len(c) < self.order else ' '.join(c[-self.order+1:])\n",
    "        return self.get_following(self.counts, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Candidator():\n",
    "    def __init__(self, dictionary, abc='йцукенгшщзхъфывапролджэячсмитьбю', check_all=True):\n",
    "        self.abc = abc\n",
    "        self.dictionary = set(dictionary)\n",
    "        self.check_all = check_all\n",
    "        \n",
    "    def edits(self, word): # mostly from norvig, modified for faster dict search\n",
    "        letters = self.abc\n",
    "        d = self.dictionary\n",
    "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "        deletes = [ed for ed in [L + R[1:] for L, R in splits if R] if ed in d]\n",
    "        transposes = [ed for ed in [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1] \\\n",
    "                      if ed in d]\n",
    "        replaces = [ed for ed in [L + c + R[1:] for L, R in splits if R for c in letters] \\\n",
    "                    if ed in d]\n",
    "        inserts = [ed for ed in [L + c + R for L, R in splits for c in letters] if ed in d]\n",
    "        return set(deletes + transposes + replaces + inserts + [word])\n",
    "    \n",
    "    def get_sentences(self, text):\n",
    "        return text.lower().split('. ')\n",
    "    \n",
    "    def word_candidates(self, sent):\n",
    "        if self.check_all:\n",
    "            return [self.edits(word) for word in sent.lower().split()]\n",
    "        else:\n",
    "            return [self.edits(word) if (word not in self.dictionary) else {word} for word in sent.lower().split()]\n",
    "    \n",
    "    def sent_candidates(self, sent):\n",
    "        return [candidate for candidate in product(*self.word_candidates(sent))]\n",
    "    \n",
    "    def candidates(self, sent):\n",
    "        return [' '.join(candidate) for candidate in self.sent_candidates(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ranker():\n",
    "    def __init__(self, lang_model, candidator):\n",
    "        self.lm = lang_model\n",
    "        self.c = candidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(s, rgxp = '[\\W\\da-z]'):\n",
    "    return re.sub(' +', ' ', re.sub(rgxp, ' ', s.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 s, sys: 337 ms, total: 2.28 s\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('corpora.txt', encoding='utf-8') as f:\n",
    "    tokens1 = cleanse(f.read().lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f = open('hagen-orf.txt', encoding='utf-8').readlines()\n",
    "d2 = [w for w in [re.findall('^ *(.+) |', l)[0].split(' | ')[0] for l in f] if len(w)>0]\n",
    "len(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = Candidator(d2, check_all=True)\n",
    "lm = LanguageModel(order=3)\n",
    "lm.fit(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.6856971271622356"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.prob('есть', log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cand_list = c.candidates('школа жлословия')\n",
    "cand_probs = sorted([(cand, lm.prob(cand, log=True)) for cand in cand_list], \n",
    "                    key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('школа злословия', -21.681645158124368),\n",
       " ('школы злословия', -22.008580075754729),\n",
       " ('школе злословия', -22.404439278478257),\n",
       " ('школу злословия', -22.83886547498442),\n",
       " ('школы жлословия', -23.263267909385149),\n",
       " ('школ злословия', -23.592321050483058),\n",
       " ('школе жлословия', -23.659127112108685),\n",
       " ('школах злословия', -23.782358219701798),\n",
       " ('школа жлословия', -23.813267069701549),\n",
       " ('школу жлословия', -24.09355330861484)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c = Candidator(d2, check_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cand_list = c.candidates('пошел на жработу')\n",
    "cand_probs = sorted([(cand, lm.prob(cand, log=True)) for cand in cand_list], \n",
    "                    key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('пошел на работу', -29.224724933416912),\n",
       " ('пошел за работу', -32.569159002246984),\n",
       " ('пошел на жработу', -33.906827092220198),\n",
       " ('пошел наш работу', -35.070000246233178),\n",
       " ('пошел та работу', -35.151055180751129),\n",
       " ('пошел га работу', -35.633803634979557),\n",
       " ('пошел сна работу', -35.666561277968881),\n",
       " ('пошел за жработу', -35.763585406652481),\n",
       " ('пошел дна работу', -35.831567315454464),\n",
       " ('пошел па работу', -35.874496138793504)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'россия'}, {'ржссия', 'россия'}, {'федерация'}, {'федерация', 'фодерация'}]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.word_candidates('россия ржссия федерация фодерация')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cand_list = c.candidates('в ржссию')\n",
    "cand_probs = sorted([(cand, lm.prob(cand, log=True)) for cand in cand_list], \n",
    "                    key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в россию', -12.528359433602237),\n",
       " ('в ржссию', -17.351424104611478),\n",
       " ('я россию', -18.277298741027003),\n",
       " ('я ржссию', -19.869779050247363),\n",
       " ('ив россию', -24.641096271347109),\n",
       " ('ив ржссию', -26.233576580567469)]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_probs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exracting bigrams from RNC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import html\n",
    "CORP_PATH = 'texts/source/post1950/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В предвкушении схватки\n",
      "ВЫБОРЫ в Госдуму состоятся в декабре. Но уже сегодня об особенностях предстоящей кампании и симпатиях избирателей можно судить по проходившим в 2002 году выборам в регионах России. Своими оценками с «АиФ» делится руководитель исследовательской группы «Меркатор» при Институте географии РАН Дмитрий ОРЕШКИН. \n",
      "Без грязи в князи \n",
      "ХОТЯ за последние годы эйфория от выборов прошла, нельзя сказать, что народ в них вовсе разочаровался. Явка избирателей снизилась в среднем всего на 1% по сравнению с предыдущим циклом выборов. Чуть апатичнее стали жители крупных городов, густонаселенных регионов. Уровень явки на выборах местных депутатов сегодня около 30% (столько пришло на участки 8 декабря в Санкт-Петербурге), губернаторов -- 40-50%. Я думаю, что выбирать Госдуму и президента придут 55-60%. Россияне по-прежнему верят, что за все происходящее в стране отвечает царь -- президент, в крайнем случае, «бояре» -- депутаты Госдумы. А потому выбирают их охотнее, чем местное начальс\n"
     ]
    }
   ],
   "source": [
    "def get_text(path):\n",
    "    with open(path) as f:\n",
    "        text = f.read().encode()\n",
    "    tree = html.fromstring(text)\n",
    "    pars = tree.xpath('.//p')\n",
    "    return '\\n'.join(par.text for par in pars)\n",
    "\n",
    "print(get_text(CORP_PATH + 'baranov/aif/aif_0109_1.xhtml')[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "from nltk import bigrams\n",
    "def bigram_fd(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_walker():\n",
    "    final_d = {}\n",
    "    for d, dirs, files in os.walk(PATH):\n",
    "        for fi in files:\n",
    "            text = get_text(os.path.join(d, fi))\n",
    "            fd = bigram_df(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
